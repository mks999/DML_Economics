{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP2noK3R0AfCz/Up0ywm4EY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mks999/DML_Economics/blob/main/Main_DML_PLR_and_Feature_Inference_PanelMultiDiD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XOqoTByT9Ir",
        "outputId": "dd239ebc-9a22-40e4-cef9-5892ea9e4f8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting doubleml\n",
            "  Downloading doubleml-0.10.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from doubleml) (1.5.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from doubleml) (1.15.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from doubleml) (0.14.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from doubleml) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.11/dist-packages (from doubleml) (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from doubleml) (5.24.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->doubleml) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->doubleml) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->doubleml) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->doubleml) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->doubleml) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->doubleml) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->doubleml) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->doubleml) (8.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->doubleml) (1.0.1)\n",
            "Downloading doubleml-0.10.0-py3-none-any.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.3/443.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: doubleml\n",
            "Successfully installed doubleml-0.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install doubleml scikit-learn pandas numpy openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/Final Imputed dataset with dummies 7.7.25.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "print(df.columns)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK4hDWxYW3Ob",
        "outputId": "dc9dcbbc-f05c-45c2-89ec-e675848b92ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['country', 'time', 'mhtx', 'rnd', 'tariff', 'mobile', 'uv_index',\n",
            "       'gfcf', 'fdi', 'lnwages', 'reer', 'd1', 'aggemp', 'ctryid',\n",
            "       'dmy_uvindex', 'dmy_mhtx', 'msch', 'internet', 'covid_dummy',\n",
            "       'L_aggemp'],\n",
            "      dtype='object')\n",
            "     country  time     mhtx       rnd  tariff    mobile  uv_index     gfcf  \\\n",
            "0  Argentina  1990  23.6244  0.472133  14.550  0.036767      40.5  13.9970   \n",
            "1  Argentina  1991  23.6244  0.472133  12.383  0.075516      50.2  14.6370   \n",
            "2  Argentina  1992  23.6244  0.450528  12.660  0.138792      52.4  16.7024   \n",
            "3  Argentina  1993  28.9722  0.441513  12.530  0.329148      52.9  19.6881   \n",
            "4  Argentina  1994  30.0064  0.436208  11.723  0.699252      57.3  19.9656   \n",
            "\n",
            "       fdi  lnwages     reer  d1  aggemp  ctryid  dmy_uvindex  dmy_mhtx  \\\n",
            "0  1.29888  22.4846  195.851   0    46.6       1          0.0       0.0   \n",
            "1  1.28558  22.7368  193.781   0    47.0       1          0.0       0.0   \n",
            "2  1.93679  22.6555  188.565   0    47.3       1          0.0       0.0   \n",
            "3  1.17980  22.7717  221.030   0    47.1       1          0.0       0.0   \n",
            "4  1.41195  22.8847  213.286   0    44.8       1          0.0       0.0   \n",
            "\n",
            "      msch  internet  covid_dummy  L_aggemp  \n",
            "0  8.12256  0.436837            0       NaN  \n",
            "1  8.19000  0.246292            0      46.6  \n",
            "2  8.25800  0.326213            0      47.0  \n",
            "3  8.32600  0.259685            0      47.3  \n",
            "4  8.39400  0.236687            0      47.1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 2: Define Variables\n",
        "# ===============================\n",
        "\n",
        "# Panel entity and time variables\n",
        "id_col = 'ctryid'      # Country identifier\n",
        "time_col = 'time'       # Time/year variable\n",
        "\n",
        "# Outcome variable\n",
        "y_col = 'aggemp'        # Aggregate employment\n",
        "\n",
        "# Treatment variable (for staggered DiD)\n",
        "treatment_col = 'mhtx'  # Main treatment variable\n",
        "\n",
        "# Control variables (as per your dataset)\n",
        "x_cols = [\n",
        "    'gfcf',       # Gross fixed capital formation\n",
        "    'rnd',        # R&D\n",
        "    'internet',   # Internet penetration\n",
        "    'mobile',     # Mobile penetration\n",
        "    'fdi',        # Foreign direct investment\n",
        "    'lnwages',    # Log of wages\n",
        "    'tariff',     # Tariff rate\n",
        "    'msch',       # Mean years of schooling\n",
        "    'reer',       # Real effective exchange rate\n",
        "\n",
        "]\n"
      ],
      "metadata": {
        "id": "_AEPfQZGW6dS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 3: Create Staggered Treatment Variable\n",
        "# ===============================\n",
        "import numpy as np\n",
        "\n",
        "def get_first_treat(subdf):\n",
        "    treated = subdf.loc[subdf[treatment_col] == 1, time_col]\n",
        "    return treated.iloc[0] if not treated.empty else np.inf\n",
        "\n",
        "df['first_treat'] = df.groupby(id_col).apply(get_first_treat).reindex(df.index).values\n",
        "\n",
        "# ===============================\n",
        "# STEP 4: Drop Missing Values in Required Columns\n",
        "# ===============================\n",
        "required_cols = [id_col, time_col, y_col, treatment_col, 'first_treat'] + x_cols\n",
        "df = df.dropna(subset=required_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5IALemxXx7v",
        "outputId": "22940a9f-3bbb-4f8f-f3ac-d7dbbed8b7a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4-1521776442.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df['first_treat'] = df.groupby(id_col).apply(get_first_treat).reindex(df.index).values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Set Up DoubleML Panel Data\n",
        "from doubleml.data import DoubleMLPanelData\n",
        "\n",
        "dml_panel_data = DoubleMLPanelData(\n",
        "    data=df,\n",
        "    y_col=y_col,\n",
        "    d_cols='first_treat',\n",
        "    id_col=id_col,\n",
        "    t_col=time_col,\n",
        "    x_cols=x_cols\n",
        ")\n"
      ],
      "metadata": {
        "id": "pk-Ho0Yw_jeS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7: Specify Machine Learning Models\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "ml_g = GradientBoostingRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_m = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42)\n"
      ],
      "metadata": {
        "id": "oh3b2XAMAGTm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 8: Fit DoubleMLDIDMulti (Staggered DiD)\n",
        "from doubleml.did import DoubleMLDIDMulti\n",
        "\n",
        "dml_did = DoubleMLDIDMulti(\n",
        "    obj_dml_data=dml_panel_data,\n",
        "    ml_g=ml_g,\n",
        "    ml_m=ml_m,\n",
        "    control_group='never_treated'\n",
        ")\n",
        "\n",
        "dml_did.fit()\n",
        "print(dml_did)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "s6_PUAXoAHvO",
        "outputId": "44b8e66b-796c-4611-9a07-a58172e175d6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No valid group-time combinations found. Please check the treatment group values and time period values (and anticipation).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-27-2828476764.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdoubleml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDoubleMLDIDMulti\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m dml_did = DoubleMLDIDMulti(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mobj_dml_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdml_panel_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mml_g\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mml_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/doubleml/did/did_multi.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj_dml_data, ml_g, ml_m, gt_combinations, control_group, anticipation_periods, n_folds, n_rep, score, in_sample_normalization, trimming_rule, trimming_threshold, draw_sample_splitting, print_periods)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_anticipation_periods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_anticipation_periods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manticipation_periods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gt_combinations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_gt_combinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_combinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gt_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_construct_gt_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_combinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_treatment_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_construct_post_treatment_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/doubleml/did/did_multi.py\u001b[0m in \u001b[0;36m_validate_gt_combinations\u001b[0;34m(self, gt_combinations)\u001b[0m\n\u001b[1;32m   1210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_combinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m             gt_combinations = _construct_gt_combinations(\n\u001b[0m\u001b[1;32m   1213\u001b[0m                 \u001b[0mgt_combinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnever_treated_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manticipation_periods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/doubleml/did/utils/_did_utils.py\u001b[0m in \u001b[0;36m_construct_gt_combinations\u001b[0;34m(setting, g_values, t_values, never_treated_value, anticipation_periods)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_combinations\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;34m\"No valid group-time combinations found. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;34m\"Please check the treatment group values and time period values (and anticipation).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No valid group-time combinations found. Please check the treatment group values and time period values (and anticipation)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#New DML_IRM INstance Run\n",
        "!pip install doubleml scikit-learn pandas numpy openpyxl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqn7h2noFOlo",
        "outputId": "362d34b3-a8ec-43df-f064-beed8f69a941"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: doubleml in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from doubleml) (1.5.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from doubleml) (1.15.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from doubleml) (0.14.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from doubleml) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.11/dist-packages (from doubleml) (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from doubleml) (5.24.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->doubleml) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->doubleml) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->doubleml) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->doubleml) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->doubleml) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->doubleml) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->doubleml) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->doubleml) (8.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->doubleml) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/Final Imputed dataset with dummies 7.7.25.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "print(df.columns)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N36cmnTOFbYr",
        "outputId": "5aaf3526-7ced-44ce-8c60-2982672690a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['country', 'time', 'mhtx', 'rnd', 'tariff', 'mobile', 'uv_index',\n",
            "       'gfcf', 'fdi', 'lnwages', 'reer', 'd1', 'aggemp', 'ctryid',\n",
            "       'dmy_uvindex', 'dmy_mhtx', 'msch', 'internet', 'covid_dummy',\n",
            "       'L_aggemp'],\n",
            "      dtype='object')\n",
            "     country  time     mhtx       rnd  tariff    mobile  uv_index     gfcf  \\\n",
            "0  Argentina  1990  23.6244  0.472133  14.550  0.036767      40.5  13.9970   \n",
            "1  Argentina  1991  23.6244  0.472133  12.383  0.075516      50.2  14.6370   \n",
            "2  Argentina  1992  23.6244  0.450528  12.660  0.138792      52.4  16.7024   \n",
            "3  Argentina  1993  28.9722  0.441513  12.530  0.329148      52.9  19.6881   \n",
            "4  Argentina  1994  30.0064  0.436208  11.723  0.699252      57.3  19.9656   \n",
            "\n",
            "       fdi  lnwages     reer  d1  aggemp  ctryid  dmy_uvindex  dmy_mhtx  \\\n",
            "0  1.29888  22.4846  195.851   0    46.6       1          0.0       0.0   \n",
            "1  1.28558  22.7368  193.781   0    47.0       1          0.0       0.0   \n",
            "2  1.93679  22.6555  188.565   0    47.3       1          0.0       0.0   \n",
            "3  1.17980  22.7717  221.030   0    47.1       1          0.0       0.0   \n",
            "4  1.41195  22.8847  213.286   0    44.8       1          0.0       0.0   \n",
            "\n",
            "      msch  internet  covid_dummy  L_aggemp  \n",
            "0  8.12256  0.436837            0       NaN  \n",
            "1  8.19000  0.246292            0      46.6  \n",
            "2  8.25800  0.326213            0      47.0  \n",
            "3  8.32600  0.259685            0      47.3  \n",
            "4  8.39400  0.236687            0      47.1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Panel entity and time variables\n",
        "id_col = 'country'\n",
        "time_col = 'time'\n",
        "\n",
        "# Outcome and treatment\n",
        "y_col = 'aggemp'\n",
        "treatment_col = 'mhtx'\n",
        "\n",
        "# Controls (update if needed)\n",
        "x_cols = [\n",
        "    'gfcf', 'rnd', 'internet', 'mobile', 'fdi',\n",
        "    'lnwages', 'tariff', 'msch', 'reer', 'covid_dummy'\n",
        "]\n"
      ],
      "metadata": {
        "id": "3HhBTfxCFcqw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop missing values in required columns\n",
        "required_cols = [y_col, treatment_col] + x_cols\n",
        "df_irm = df[required_cols].dropna()\n"
      ],
      "metadata": {
        "id": "IWDQa61yFp-0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from doubleml import DoubleMLData\n",
        "\n",
        "dml_data_irm = DoubleMLData(df_irm, y_col=y_col, d_cols=treatment_col, x_cols=x_cols)\n"
      ],
      "metadata": {
        "id": "hgeXCmbEFurS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "ml_g = GradientBoostingRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_m = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42)\n"
      ],
      "metadata": {
        "id": "HzHfHvcxF3QV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db4114c9"
      },
      "source": [
        "### DoubleML PLR with Continuous Treatment\n",
        "\n",
        "Here's the code to implement the Partially Linear Regression (PLR) model using DoubleML, with `mhtx` as the continuous treatment variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b869cd5",
        "outputId": "0326a229-9a19-421d-a893-a23825ea8faf"
      },
      "source": [
        "from doubleml import DoubleMLData, DoubleMLPLR\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "# Prepare your data as before\n",
        "y_col = 'aggemp'\n",
        "treatment_col = 'mhtx' # mhtx is a continuous treatment variable\n",
        "x_cols = [\n",
        "    'gfcf', 'rnd', 'internet', 'mobile', 'fdi',\n",
        "    'lnwages', 'tariff', 'msch', 'reer', 'covid_dummy' # Removed 'uv_index'\n",
        "]\n",
        "\n",
        "# Drop missing values in required columns\n",
        "df_plr = df[[y_col, treatment_col] + x_cols].dropna()\n",
        "\n",
        "# Set up DoubleML Data for PLR\n",
        "dml_data = DoubleMLData(df_plr, y_col=y_col, d_cols=treatment_col, x_cols=x_cols)\n",
        "\n",
        "# Specify Machine Learning Models\n",
        "ml_g = GradientBoostingRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_m = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_l = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "\n",
        "# Fit DoubleMLPLR\n",
        "# Removed store_models=True from constructor\n",
        "dml_plr = DoubleMLPLR(\n",
        "    dml_data,\n",
        "    ml_g=ml_g,\n",
        "    ml_m=ml_m,\n",
        "    ml_l=ml_l\n",
        ")\n",
        "# Added store_models=True to the fit method\n",
        "dml_plr.fit(store_models=True)\n",
        "\n",
        "# Print the summary of the results\n",
        "print(dml_plr.summary)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/doubleml/plm/plr.py:109: UserWarning: A learner ml_g has been provided for score = \"partialling out\" but will be ignored. \"A learner ml_g is not required for estimation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          coef   std err         t     P>|t|     2.5 %    97.5 %\n",
            "mhtx -0.032724  0.011889 -2.752372  0.005917 -0.056026 -0.009421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from doubleml import DoubleMLData, DoubleMLPLR\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "# Prepare your data as before\n",
        "y_col = 'aggemp'\n",
        "treatment_col = 'mhtx' # mhtx is a continuous treatment variable\n",
        "x_cols = [\n",
        "    'gfcf', 'rnd', 'internet', 'mobile', 'fdi',\n",
        "    'lnwages', 'tariff', 'msch', 'reer'\n",
        "]\n",
        "\n",
        "# Drop missing values in required columns\n",
        "df_plr = df[[y_col, treatment_col] + x_cols].dropna()\n",
        "\n",
        "# Set up DoubleML Data for PLR\n",
        "dml_data = DoubleMLData(df_plr, y_col=y_col, d_cols=treatment_col, x_cols=x_cols)\n",
        "\n",
        "# Specify Machine Learning Models\n",
        "ml_g = GradientBoostingRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_m = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_l = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42) # Added ml_l\n",
        "\n",
        "# Fit DoubleMLPLR\n",
        "dml_plr = DoubleMLPLR(dml_data, ml_g=ml_g, ml_m=ml_m, ml_l=ml_l) # Added ml_l argument\n",
        "# Added store_models=True to the fit method\n",
        "dml_plr.fit(store_models=True)\n",
        "\n",
        "\n",
        "# Print the summary of the results\n",
        "print(dml_plr.summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vuUObDmXEf8",
        "outputId": "4b5f6495-9f22-4499-daad-6066a7a77ed2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/doubleml/plm/plr.py:109: UserWarning: A learner ml_g has been provided for score = \"partialling out\" but will be ignored. \"A learner ml_g is not required for estimation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          coef   std err        t     P>|t|     2.5 %    97.5 %\n",
            "mhtx -0.034649  0.011984 -2.89132  0.003836 -0.058137 -0.011161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from doubleml import DoubleMLData, DoubleMLPLR\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "# Prepare your data as before\n",
        "y_col = 'aggemp'\n",
        "treatment_col = 'mhtx' # mhtx is a continuous treatment variable\n",
        "x_cols = [\n",
        "    'gfcf', 'rnd', 'internet', 'mobile', 'fdi',\n",
        "    'lnwages', 'tariff', 'msch', 'reer', 'covid_dummy', 'dmy_mhtx'\n",
        "]\n",
        "\n",
        "# Drop missing values in required columns\n",
        "df_plr = df[[y_col, treatment_col] + x_cols].dropna()\n",
        "\n",
        "# Set up DoubleML Data for PLR\n",
        "dml_data = DoubleMLData(df_plr, y_col=y_col, d_cols=treatment_col, x_cols=x_cols)\n",
        "\n",
        "# Specify Machine Learning Models\n",
        "ml_g = GradientBoostingRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_m = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_l = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42) # Added ml_l\n",
        "\n",
        "# Fit DoubleMLPLR\n",
        "dml_plr = DoubleMLPLR(dml_data, ml_g=ml_g, ml_m=ml_m, ml_l=ml_l) # Added ml_l argument\n",
        "# Added store_models=True to the fit method\n",
        "dml_plr.fit(store_models=True)\n",
        "\n",
        "\n",
        "# Print the summary of the results\n",
        "print(dml_plr.summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wedh_MSqXMZm",
        "outputId": "dd396740-9f7b-4078-9d83-49a044279858"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/doubleml/plm/plr.py:109: UserWarning: A learner ml_g has been provided for score = \"partialling out\" but will be ignored. \"A learner ml_g is not required for estimation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          coef   std err         t     P>|t|     2.5 %    97.5 %\n",
            "mhtx  0.045272  0.013092  3.457864  0.000544  0.019611  0.070933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe20b623"
      },
      "source": [
        "### Inspecting Feature Importance of Control Variables\n",
        "\n",
        "While DoubleML PLR doesn't provide coefficients for control variables in the final output, you can inspect the fitted first-stage models (`ml_g`, `ml_m`, and `ml_l`) to see the importance of each control variable in predicting the outcome and treatment.\n",
        "\n",
        "For tree-based models like the ones used (`GradientBoostingRegressor` and `RandomForestRegressor`), feature importance is a relevant metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0875180b"
      },
      "source": [
        "### Inspecting Feature Importance of Control Variables\n",
        "\n",
        "Now that the `DoubleMLPLR` model has been fitted with `store_models=True`, we can access the fitted first-stage models (`ml_g`, `ml_m`, and `ml_l`) to see the importance of each control variable in predicting the outcome and treatment.\n",
        "\n",
        "For the tree-based models used (`GradientBoostingRegressor` and `RandomForestRegressor`), feature importance is a relevant metric to understand which variables were most influential in the first-stage predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e830267e"
      },
      "source": [
        "### Corrected DoubleML PLR Fit and Feature Importance Display\n",
        "\n",
        "This code block combines the initialization and fitting of the `DoubleMLPLR` model with the correct method for storing fitted models (`store_models=True` in the `.fit()` method), and then accesses and displays the feature importances of the first-stage models.\n",
        "\n",
        "Ensure that `df_plr`, `y_col`, `treatment_col`, and `x_cols` are defined in previous cells before running this code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21b35623"
      },
      "source": [
        "### DoubleML PLR with Model Inspection and Feature Importance Extraction\n",
        "\n",
        "This code block performs the following steps:\n",
        "1.  Prepares the data, defining outcome, treatment, and control variables.\n",
        "2.  Initializes and fits the `DoubleMLPLR` model, ensuring fitted models are stored using `fit(store_models=True)`.\n",
        "3.  Prints the main `DoubleMLPLR` results summary.\n",
        "4.  Inspects and prints the nested structure of the `dml_plr.models` attribute to understand how fitted base learners are stored.\n",
        "5.  Includes a function to collect feature importances from the nested model structure across all repetitions and folds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6b21281",
        "outputId": "94cd3b18-91ae-4b9a-ccf7-779be69b7609"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from doubleml import DoubleMLData, DoubleMLPLR\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 1.  PREPARE DATA  (use your own path / variable names)\n",
        "# ------------------------------------------------------------------\n",
        "file_path = '/content/Final Imputed dataset with dummies 7.7.25.xlsx'\n",
        "df        = pd.read_excel(file_path)\n",
        "\n",
        "y_col         = 'aggemp'\n",
        "treatment_col = 'mhtx'\n",
        "x_cols = [\n",
        "    'uv_index', 'gfcf', 'rnd', 'internet', 'mobile', 'fdi',\n",
        "    'lnwages', 'tariff', 'msch', 'reer', 'covid_dummy'\n",
        "]\n",
        "\n",
        "df_plr = df[[y_col, treatment_col] + x_cols].dropna()\n",
        "dml_data = DoubleMLData(df_plr, y_col=y_col, d_cols=treatment_col, x_cols=x_cols)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 2.  FIT DOUBLEML-PLR  (store fitted models)\n",
        "# ------------------------------------------------------------------\n",
        "ml_l = GradientBoostingRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_m = RandomForestRegressor(n_estimators=200,  max_depth=4, random_state=42)\n",
        "\n",
        "dml_plr = DoubleMLPLR(dml_data, ml_l=ml_l, ml_m=ml_m, n_folds=5, n_rep=1)\n",
        "dml_plr.fit(store_models=True)          # <- critical line\n",
        "\n",
        "print('\\nDoubleMLPLR main results\\n', dml_plr.summary, '\\n')\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 3.  INSPECT THE NESTED \"models\" STRUCTURE\n",
        "# ------------------------------------------------------------------\n",
        "# Print the full models structure to diagnose the KeyError\n",
        "print(\"Full dml_plr.models structure:\")\n",
        "print(dml_plr.models)\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 4.  FEATURE-IMPORTANCE EXTRACTION (ALL REPS / FOLDS)\n",
        "# ------------------------------------------------------------------\n",
        "def collect_importances(nuisance_key):\n",
        "    \"\"\"Return a (rep,fold,feature) DataFrame of importances for one nuisance.\"\"\"\n",
        "    records = []\n",
        "    # Iterate over repetitions (n_rep in dml_plr)\n",
        "    for rep_idx in range(dml_plr.n_rep):\n",
        "        # Access the list of fold models for this repetition and treatment variable\n",
        "        # Structure is dml_plr.models[nuisance_key][treatment_col][rep_idx]\n",
        "        if treatment_col not in dml_plr.models[nuisance_key]:\n",
        "             print(f\"Warning: Treatment column '{treatment_col}' not found for nuisance key '{nuisance_key}' in dml_plr.models structure.\")\n",
        "             continue\n",
        "\n",
        "        fold_models_list = dml_plr.models[nuisance_key][treatment_col][rep_idx]\n",
        "\n",
        "        # Iterate over folds (n_folds in dml_plr)\n",
        "        for fold_idx in range(dml_plr.n_folds):\n",
        "            # Access the fitted model for this fold within the repetition list\n",
        "            fitted_model = fold_models_list[fold_idx]\n",
        "\n",
        "            if hasattr(fitted_model, 'feature_importances_'):\n",
        "                importances = fitted_model.feature_importances_\n",
        "                # Determine feature names based on the model (ml_l includes treatment_col)\n",
        "                if nuisance_key == 'ml_l':\n",
        "                    # Features for ml_l are x_cols + [treatment_col]\n",
        "                    feature_names = x_cols + [treatment_col]\n",
        "                elif nuisance_key == 'ml_m':\n",
        "                    # Features for ml_m are x_cols\n",
        "                    feature_names = x_cols\n",
        "                else:\n",
        "                    continue # Should not happen with ml_l and ml_m\n",
        "\n",
        "                # Ensure feature names match importance count\n",
        "                if len(feature_names) != len(importances):\n",
        "                    print(f\"Warning: Feature names count ({len(feature_names)}) does not match importance count ({len(importances)}) for nuisance key '{nuisance_key}', rep {rep_idx}, fold {fold_idx}. Skipping.\")\n",
        "                    continue\n",
        "\n",
        "\n",
        "                for feature_name, importance in zip(feature_names, importances):\n",
        "                    records.append({\n",
        "                        'nuisance': nuisance_key,\n",
        "                        'rep': rep_idx,\n",
        "                        'fold': fold_idx,\n",
        "                        'feature': feature_name,\n",
        "                        'importance': importance\n",
        "                    })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "# Now call the function for ml_l and ml_m\n",
        "try:\n",
        "    importance_ml_l_df = collect_importances('ml_l')\n",
        "    if not importance_ml_l_df.empty:\n",
        "        print(\"\\nFeature Importances for ml_l (Outcome Model) across folds and repetitions:\")\n",
        "        print(importance_ml_l_df.groupby('feature')['importance'].mean().sort_values(ascending=False))\n",
        "    else:\n",
        "         print(\"\\nNo feature importance data collected for ml_l.\")\n",
        "except Exception as e:\n",
        "     print(f\"\\nAn error occurred while collecting importances for ml_l: {e}\")\n",
        "\n",
        "\n",
        "try:\n",
        "    importance_ml_m_df = collect_importances('ml_m')\n",
        "    if not importance_ml_m_df.empty:\n",
        "        print(\"\\nFeature Importances for ml_m (Treatment Model) across folds and repetitions:\")\n",
        "        print(importance_ml_m_df.groupby('feature')['importance'].mean().sort_values(ascending=False))\n",
        "    else:\n",
        "         print(\"\\nNo feature importance data collected for ml_m.\")\n",
        "except Exception as e:\n",
        "     print(f\"\\nAn error occurred while collecting importances for ml_m: {e}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DoubleMLPLR main results\n",
            "           coef   std err         t     P>|t|     2.5 %    97.5 %\n",
            "mhtx -0.020792  0.007177 -2.896933  0.003768 -0.034859 -0.006725 \n",
            "\n",
            "Full dml_plr.models structure:\n",
            "{'ml_l': {'mhtx': [[GradientBoostingRegressor(max_depth=4, n_estimators=200, random_state=42), GradientBoostingRegressor(max_depth=4, n_estimators=200, random_state=42), GradientBoostingRegressor(max_depth=4, n_estimators=200, random_state=42), GradientBoostingRegressor(max_depth=4, n_estimators=200, random_state=42), GradientBoostingRegressor(max_depth=4, n_estimators=200, random_state=42)]]}, 'ml_m': {'mhtx': [[RandomForestRegressor(max_depth=4, n_estimators=200, random_state=42), RandomForestRegressor(max_depth=4, n_estimators=200, random_state=42), RandomForestRegressor(max_depth=4, n_estimators=200, random_state=42), RandomForestRegressor(max_depth=4, n_estimators=200, random_state=42), RandomForestRegressor(max_depth=4, n_estimators=200, random_state=42)]]}}\n",
            "------------------------------------------------------------\n",
            "Warning: Feature names count (12) does not match importance count (11) for nuisance key 'ml_l', rep 0, fold 0. Skipping.\n",
            "Warning: Feature names count (12) does not match importance count (11) for nuisance key 'ml_l', rep 0, fold 1. Skipping.\n",
            "Warning: Feature names count (12) does not match importance count (11) for nuisance key 'ml_l', rep 0, fold 2. Skipping.\n",
            "Warning: Feature names count (12) does not match importance count (11) for nuisance key 'ml_l', rep 0, fold 3. Skipping.\n",
            "Warning: Feature names count (12) does not match importance count (11) for nuisance key 'ml_l', rep 0, fold 4. Skipping.\n",
            "\n",
            "No feature importance data collected for ml_l.\n",
            "\n",
            "Feature Importances for ml_m (Treatment Model) across folds and repetitions:\n",
            "feature\n",
            "rnd            0.555258\n",
            "lnwages        0.164589\n",
            "tariff         0.078177\n",
            "uv_index       0.053703\n",
            "msch           0.048188\n",
            "mobile         0.029975\n",
            "gfcf           0.027746\n",
            "fdi            0.022683\n",
            "internet       0.011902\n",
            "reer           0.007574\n",
            "covid_dummy    0.000204\n",
            "Name: importance, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from doubleml import DoubleMLData, DoubleMLPLR\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "# Load your data (adjust path as needed)\n",
        "file_path = '/content/Final Imputed dataset with dummies 7.7.25.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Define variables using your actual column names\n",
        "y_col = 'aggemp'\n",
        "treatment_col = 'mhtx'\n",
        "x_cols = [\n",
        "    'uv_index', 'gfcf', 'rnd', 'internet', 'mobile', 'fdi',\n",
        "    'lnwages', 'tariff', 'msch', 'reer', 'covid_dummy'\n",
        "]\n",
        "\n",
        "# Prepare data\n",
        "required_cols = [y_col, treatment_col] + x_cols\n",
        "df_plr = df[required_cols].dropna()\n",
        "\n",
        "# Create DoubleMLData object\n",
        "dml_data = DoubleMLData(df_plr, y_col=y_col, d_cols=treatment_col, x_cols=x_cols)\n",
        "\n",
        "# Define ML learners\n",
        "ml_l = GradientBoostingRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_m = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "\n",
        "# Initialize DoubleMLPLR (do NOT include ml_g for 'partialling out' score)\n",
        "dml_plr = DoubleMLPLR(dml_data, ml_l=ml_l, ml_m=ml_m)\n",
        "\n",
        "# Fit the model with store_models=True to access fitted models\n",
        "dml_plr.fit(store_models=True)\n",
        "\n",
        "# Print main results\n",
        "print(\"DoubleMLPLR Main Results Summary:\")\n",
        "print(dml_plr.summary)\n",
        "\n",
        "# Access fitted models for feature importance\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check if models are stored\n",
        "if dml_plr.models is not None:\n",
        "    # Access fitted models for the first fold of the first repetition\n",
        "    # Structure is dml_plr.models[nuisance_key][treatment_col][rep_idx][fold_idx]\n",
        "    fitted_ml_l = dml_plr.models['ml_l'][treatment_col][0][0]\n",
        "    fitted_ml_m = dml_plr.models['ml_m'][treatment_col][0][0]\n",
        "\n",
        "\n",
        "    # Display feature importances for ml_l (outcome model)\n",
        "    print(\"\\nFeature importances for ml_l (outcome model - predicting Y|X):\")\n",
        "    if hasattr(fitted_ml_l, 'feature_importances_'):\n",
        "        # Features for ml_l are x_cols + [treatment_col]\n",
        "        all_features_l = x_cols + [treatment_col]\n",
        "        if len(fitted_ml_l.feature_importances_) == len(all_features_l):\n",
        "             feature_importances_l = pd.Series(fitted_ml_l.feature_importances_, index=all_features_l)\n",
        "             print(feature_importances_l.sort_values(ascending=False))\n",
        "        else:\n",
        "            print(f\"Feature importance count ({len(fitted_ml_l.feature_importances_)}) does not match expected feature count ({len(all_features_l)}). Cannot display with names.\")\n",
        "            print(fitted_ml_l.feature_importances_)\n",
        "\n",
        "    else:\n",
        "        print(\"The ml_l model does not have a feature_importances_ attribute.\")\n",
        "\n",
        "    # Display feature importances for ml_m (treatment model)\n",
        "    print(\"\\nFeature importances for ml_m (treatment model - predicting D|X):\")\n",
        "    if hasattr(fitted_ml_m, 'feature_importances_'):\n",
        "         # Features for ml_m are x_cols\n",
        "        if len(fitted_ml_m.feature_importances_) == len(x_cols):\n",
        "            feature_importances_m = pd.Series(fitted_ml_m.feature_importances_, index=x_cols)\n",
        "            print(feature_importances_m.sort_values(ascending=False))\n",
        "        else:\n",
        "            print(f\"Feature importance count ({len(fitted_ml_m.feature_importances_)}) does not match expected feature count ({len(x_cols)}). Cannot display with names.\")\n",
        "            print(fitted_ml_m.feature_importances_)\n",
        "    else:\n",
        "        print(\"The ml_m model does not have a feature_importances_ attribute.\")\n",
        "\n",
        "    # Create a comparison DataFrame (only if both importances were successfully named)\n",
        "    if (hasattr(fitted_ml_l, 'feature_importances_') and len(fitted_ml_l.feature_importances_) == len(all_features_l) and\n",
        "        hasattr(fitted_ml_m, 'feature_importances_') and len(fitted_ml_m.feature_importances_) == len(x_cols)):\n",
        "\n",
        "        print(\"\\nFeature Importance Comparison (First Fold, First Repetition):\")\n",
        "        # Align features for comparison - this might be tricky if ml_l feature order is unexpected\n",
        "        # Assuming x_cols order is consistent, we can compare importances for x_cols in both models\n",
        "        comparison_df = pd.DataFrame({\n",
        "            'Outcome_Model_Importance (ml_l, predicting Y|D,X)': feature_importances_l.drop(treatment_col, errors='ignore'), # Drop treatment from ml_l for X comparison\n",
        "            'Treatment_Model_Importance (ml_m, predicting D|X)': feature_importances_m\n",
        "        })\n",
        "        comparison_df = comparison_df.sort_values('Outcome_Model_Importance (ml_l, predicting Y|D,X)', ascending=False)\n",
        "        print(comparison_df.round(4))\n",
        "\n",
        "else:\n",
        "    print(\"Models were not stored. Make sure to use fit(store_models=True)\")\n",
        "\n",
        "# Additional analysis: Feature importance across all folds - This requires iterating through the structure.\n",
        "# The collect_importances function from cell d6b21281 is designed for this.\n",
        "# If you want to see average importances across all folds/reps, use that function."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dx8YTK6os8N",
        "outputId": "4b52ec0e-8a9e-4809-b02a-dfbb97d92851"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DoubleMLPLR Main Results Summary:\n",
            "          coef   std err         t     P>|t|    2.5 %    97.5 %\n",
            "mhtx -0.018969  0.007899 -2.401627  0.016322 -0.03445 -0.003489\n",
            "\n",
            "============================================================\n",
            "FEATURE IMPORTANCE ANALYSIS\n",
            "============================================================\n",
            "\n",
            "Feature importances for ml_l (outcome model - predicting Y|X):\n",
            "Feature importance count (11) does not match expected feature count (12). Cannot display with names.\n",
            "[0.04097229 0.13943842 0.19390447 0.04411581 0.03638213 0.05347868\n",
            " 0.1971535  0.07277085 0.17365881 0.04783531 0.00028973]\n",
            "\n",
            "Feature importances for ml_m (treatment model - predicting D|X):\n",
            "rnd            0.565561\n",
            "lnwages        0.156516\n",
            "tariff         0.069304\n",
            "uv_index       0.056472\n",
            "msch           0.047034\n",
            "fdi            0.027531\n",
            "gfcf           0.025926\n",
            "mobile         0.022725\n",
            "internet       0.019922\n",
            "reer           0.008971\n",
            "covid_dummy    0.000039\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from doubleml import DoubleMLData, DoubleMLPLR\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "# Prepare your data as before\n",
        "y_col = 'aggemp'\n",
        "treatment_col = 'uv_index' # mhtx is a continuous treatment variable\n",
        "x_cols = [\n",
        "    'gfcf', 'rnd', 'internet', 'mobile', 'fdi',\n",
        "    'lnwages', 'tariff', 'msch', 'reer', 'covid_dummy' # Removed 'uv_index'\n",
        "]\n",
        "\n",
        "# Drop missing values in required columns\n",
        "df_plr = df[[y_col, treatment_col] + x_cols].dropna()\n",
        "\n",
        "# Set up DoubleML Data for PLR\n",
        "dml_data = DoubleMLData(df_plr, y_col=y_col, d_cols=treatment_col, x_cols=x_cols)\n",
        "\n",
        "# Specify Machine Learning Models\n",
        "ml_g = GradientBoostingRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_m = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_l = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "\n",
        "# Fit DoubleMLPLR\n",
        "# Removed store_models=True from constructor\n",
        "dml_plr = DoubleMLPLR(\n",
        "    dml_data,\n",
        "    ml_g=ml_g,\n",
        "    ml_m=ml_m,\n",
        "    ml_l=ml_l\n",
        ")\n",
        "# Added store_models=True to the fit method\n",
        "dml_plr.fit(store_models=True)\n",
        "\n",
        "# Print the summary of the results\n",
        "print(dml_plr.summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CycnWp925bok",
        "outputId": "43471246-3cb6-4b75-960a-ad3fc4a6a23d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/doubleml/plm/plr.py:109: UserWarning: A learner ml_g has been provided for score = \"partialling out\" but will be ignored. \"A learner ml_g is not required for estimation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              coef   std err         t     P>|t|     2.5 %    97.5 %\n",
            "uv_index  0.006654  0.008699  0.764946  0.444304 -0.010395  0.023704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "x0XtuEJH6Cn6",
        "outputId": "e7f084f2-7da1-426b-b88d-d3b5f1dc3a22"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     country  time     mhtx       rnd  tariff    mobile  uv_index     gfcf  \\\n",
              "0  Argentina  1990  23.6244  0.472133  14.550  0.036767      40.5  13.9970   \n",
              "1  Argentina  1991  23.6244  0.472133  12.383  0.075516      50.2  14.6370   \n",
              "2  Argentina  1992  23.6244  0.450528  12.660  0.138792      52.4  16.7024   \n",
              "3  Argentina  1993  28.9722  0.441513  12.530  0.329148      52.9  19.6881   \n",
              "4  Argentina  1994  30.0064  0.436208  11.723  0.699252      57.3  19.9656   \n",
              "\n",
              "       fdi  lnwages     reer  d1  aggemp  ctryid  dmy_uvindex  dmy_mhtx  \\\n",
              "0  1.29888  22.4846  195.851   0    46.6       1          0.0       0.0   \n",
              "1  1.28558  22.7368  193.781   0    47.0       1          0.0       0.0   \n",
              "2  1.93679  22.6555  188.565   0    47.3       1          0.0       0.0   \n",
              "3  1.17980  22.7717  221.030   0    47.1       1          0.0       0.0   \n",
              "4  1.41195  22.8847  213.286   0    44.8       1          0.0       0.0   \n",
              "\n",
              "      msch  internet  covid_dummy  L_aggemp  \n",
              "0  8.12256  0.436837            0       NaN  \n",
              "1  8.19000  0.246292            0      46.6  \n",
              "2  8.25800  0.326213            0      47.0  \n",
              "3  8.32600  0.259685            0      47.3  \n",
              "4  8.39400  0.236687            0      47.1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-258d91f4-850a-4da6-b93e-dcb8eaf18a1c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>time</th>\n",
              "      <th>mhtx</th>\n",
              "      <th>rnd</th>\n",
              "      <th>tariff</th>\n",
              "      <th>mobile</th>\n",
              "      <th>uv_index</th>\n",
              "      <th>gfcf</th>\n",
              "      <th>fdi</th>\n",
              "      <th>lnwages</th>\n",
              "      <th>reer</th>\n",
              "      <th>d1</th>\n",
              "      <th>aggemp</th>\n",
              "      <th>ctryid</th>\n",
              "      <th>dmy_uvindex</th>\n",
              "      <th>dmy_mhtx</th>\n",
              "      <th>msch</th>\n",
              "      <th>internet</th>\n",
              "      <th>covid_dummy</th>\n",
              "      <th>L_aggemp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Argentina</td>\n",
              "      <td>1990</td>\n",
              "      <td>23.6244</td>\n",
              "      <td>0.472133</td>\n",
              "      <td>14.550</td>\n",
              "      <td>0.036767</td>\n",
              "      <td>40.5</td>\n",
              "      <td>13.9970</td>\n",
              "      <td>1.29888</td>\n",
              "      <td>22.4846</td>\n",
              "      <td>195.851</td>\n",
              "      <td>0</td>\n",
              "      <td>46.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.12256</td>\n",
              "      <td>0.436837</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Argentina</td>\n",
              "      <td>1991</td>\n",
              "      <td>23.6244</td>\n",
              "      <td>0.472133</td>\n",
              "      <td>12.383</td>\n",
              "      <td>0.075516</td>\n",
              "      <td>50.2</td>\n",
              "      <td>14.6370</td>\n",
              "      <td>1.28558</td>\n",
              "      <td>22.7368</td>\n",
              "      <td>193.781</td>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.19000</td>\n",
              "      <td>0.246292</td>\n",
              "      <td>0</td>\n",
              "      <td>46.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Argentina</td>\n",
              "      <td>1992</td>\n",
              "      <td>23.6244</td>\n",
              "      <td>0.450528</td>\n",
              "      <td>12.660</td>\n",
              "      <td>0.138792</td>\n",
              "      <td>52.4</td>\n",
              "      <td>16.7024</td>\n",
              "      <td>1.93679</td>\n",
              "      <td>22.6555</td>\n",
              "      <td>188.565</td>\n",
              "      <td>0</td>\n",
              "      <td>47.3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.25800</td>\n",
              "      <td>0.326213</td>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Argentina</td>\n",
              "      <td>1993</td>\n",
              "      <td>28.9722</td>\n",
              "      <td>0.441513</td>\n",
              "      <td>12.530</td>\n",
              "      <td>0.329148</td>\n",
              "      <td>52.9</td>\n",
              "      <td>19.6881</td>\n",
              "      <td>1.17980</td>\n",
              "      <td>22.7717</td>\n",
              "      <td>221.030</td>\n",
              "      <td>0</td>\n",
              "      <td>47.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.32600</td>\n",
              "      <td>0.259685</td>\n",
              "      <td>0</td>\n",
              "      <td>47.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Argentina</td>\n",
              "      <td>1994</td>\n",
              "      <td>30.0064</td>\n",
              "      <td>0.436208</td>\n",
              "      <td>11.723</td>\n",
              "      <td>0.699252</td>\n",
              "      <td>57.3</td>\n",
              "      <td>19.9656</td>\n",
              "      <td>1.41195</td>\n",
              "      <td>22.8847</td>\n",
              "      <td>213.286</td>\n",
              "      <td>0</td>\n",
              "      <td>44.8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.39400</td>\n",
              "      <td>0.236687</td>\n",
              "      <td>0</td>\n",
              "      <td>47.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-258d91f4-850a-4da6-b93e-dcb8eaf18a1c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-258d91f4-850a-4da6-b93e-dcb8eaf18a1c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-258d91f4-850a-4da6-b93e-dcb8eaf18a1c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-889cd1ed-ca31-4946-876a-78c251476d64\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-889cd1ed-ca31-4946-876a-78c251476d64')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-889cd1ed-ca31-4946-876a-78c251476d64 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1485,\n  \"fields\": [\n    {\n      \"column\": \"country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 45,\n        \"samples\": [\n          \"Spain\",\n          \"Latvia\",\n          \"Lithuania\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 1990,\n        \"max\": 2022,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          2021,\n          2005,\n          2016\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mhtx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.323179389272614,\n        \"min\": 7.60209,\n        \"max\": 85.3884,\n        \"num_unique_values\": 1429,\n        \"samples\": [\n          53.635,\n          62.9599,\n          72.5248\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rnd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9832103875412032,\n        \"min\": 0.0423,\n        \"max\": 6.01924,\n        \"num_unique_values\": 1471,\n        \"samples\": [\n          1.32419,\n          1.82504,\n          1.41778\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tariff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.5152714251137525,\n        \"min\": 0.0,\n        \"max\": 56.36,\n        \"num_unique_values\": 804,\n        \"samples\": [\n          14.46,\n          6.768,\n          3.95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mobile\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52.644550325117905,\n        \"min\": 0.0,\n        \"max\": 179.099,\n        \"num_unique_values\": 1453,\n        \"samples\": [\n          94.232,\n          168.985,\n          114.69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"uv_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27.870530090392766,\n        \"min\": 25.6,\n        \"max\": 236.3,\n        \"num_unique_values\": 933,\n        \"samples\": [\n          125.1,\n          60.5,\n          60.07\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gfcf\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.434801930642083,\n        \"min\": 10.8539,\n        \"max\": 53.7136,\n        \"num_unique_values\": 1479,\n        \"samples\": [\n          15.4692,\n          16.0323,\n          30.1372\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fdi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.822173264727748,\n        \"min\": -440.131,\n        \"max\": 234.249,\n        \"num_unique_values\": 1485,\n        \"samples\": [\n          -2.82644,\n          1.57899,\n          4.85956\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lnwages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3759959720586488,\n        \"min\": 19.1103,\n        \"max\": 26.9556,\n        \"num_unique_values\": 1454,\n        \"samples\": [\n          23.4002,\n          24.3709,\n          22.5841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.790272750279915,\n        \"min\": 13.712,\n        \"max\": 234.984,\n        \"num_unique_values\": 1434,\n        \"samples\": [\n          107.522,\n          156.978,\n          98.91\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"d1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aggemp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.747396077280504,\n        \"min\": 27.7,\n        \"max\": 82.223,\n        \"num_unique_values\": 1437,\n        \"samples\": [\n          55.337,\n          58.881\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ctryid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 1,\n        \"max\": 45,\n        \"num_unique_values\": 45,\n        \"samples\": [\n          40,\n          26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dmy_uvindex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 48.12106178175184,\n        \"min\": 0.0,\n        \"max\": 236.3,\n        \"num_unique_values\": 715,\n        \"samples\": [\n          105.1,\n          138.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dmy_mhtx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27.53670971571303,\n        \"min\": 0.0,\n        \"max\": 85.3884,\n        \"num_unique_values\": 987,\n        \"samples\": [\n          72.1077,\n          56.6102\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"msch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.4333003595089626,\n        \"min\": 2.78057,\n        \"max\": 14.2964,\n        \"num_unique_values\": 1176,\n        \"samples\": [\n          10.7358,\n          11.09\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"internet\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.70311815206687,\n        \"min\": 0.000585,\n        \"max\": 48.2502,\n        \"num_unique_values\": 1467,\n        \"samples\": [\n          11.2414,\n          31.6318\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"covid_dummy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"L_aggemp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.7800082454403965,\n        \"min\": 27.7,\n        \"max\": 82.223,\n        \"num_unique_values\": 1396,\n        \"samples\": [\n          50.212,\n          52.177\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from doubleml import DoubleMLData, DoubleMLPLR\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "# Prepare your data as before\n",
        "y_col = 'aggemp'\n",
        "treatment_col = 'uv_index' # mhtx is a continuous treatment variable\n",
        "x_cols = [\n",
        "    'gfcf', 'rnd', 'internet', 'mobile', 'fdi',\n",
        "    'lnwages', 'tariff', 'msch', 'reer'\n",
        "]\n",
        "\n",
        "# Drop missing values in required columns\n",
        "df_plr = df[[y_col, treatment_col] + x_cols].dropna()\n",
        "\n",
        "# Set up DoubleML Data for PLR\n",
        "dml_data = DoubleMLData(df_plr, y_col=y_col, d_cols=treatment_col, x_cols=x_cols)\n",
        "\n",
        "# Specify Machine Learning Models\n",
        "ml_g = GradientBoostingRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_m = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_l = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42) # Added ml_l\n",
        "\n",
        "# Fit DoubleMLPLR\n",
        "dml_plr = DoubleMLPLR(dml_data, ml_g=ml_g, ml_m=ml_m, ml_l=ml_l) # Added ml_l argument\n",
        "# Added store_models=True to the fit method\n",
        "dml_plr.fit(store_models=True)\n",
        "\n",
        "\n",
        "# Print the summary of the results\n",
        "print(dml_plr.summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5ir7NGl5irB",
        "outputId": "313f34ad-53e6-417b-ab13-abfc5047e438"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/doubleml/plm/plr.py:109: UserWarning: A learner ml_g has been provided for score = \"partialling out\" but will be ignored. \"A learner ml_g is not required for estimation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              coef   std err         t   P>|t|     2.5 %    97.5 %\n",
            "uv_index  0.008241  0.008498  0.969693  0.3322 -0.008416  0.024897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from doubleml import DoubleMLData, DoubleMLPLR\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "# Prepare your data as before\n",
        "y_col = 'aggemp'\n",
        "treatment_col = 'uv_index' # mhtx is a continuous treatment variable\n",
        "x_cols = [\n",
        "    'gfcf', 'rnd', 'internet', 'mobile', 'fdi',\n",
        "    'lnwages', 'tariff', 'msch', 'reer', 'covid_dummy', 'dmy_uvindex'\n",
        "]\n",
        "\n",
        "# Drop missing values in required columns\n",
        "df_plr = df[[y_col, treatment_col] + x_cols].dropna()\n",
        "\n",
        "# Set up DoubleML Data for PLR\n",
        "dml_data = DoubleMLData(df_plr, y_col=y_col, d_cols=treatment_col, x_cols=x_cols)\n",
        "\n",
        "# Specify Machine Learning Models\n",
        "ml_g = GradientBoostingRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_m = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_l = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42) # Added ml_l\n",
        "\n",
        "# Fit DoubleMLPLR\n",
        "dml_plr = DoubleMLPLR(dml_data, ml_g=ml_g, ml_m=ml_m, ml_l=ml_l) # Added ml_l argument\n",
        "# Added store_models=True to the fit method\n",
        "dml_plr.fit(store_models=True)\n",
        "\n",
        "\n",
        "# Print the summary of the results\n",
        "print(dml_plr.summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3IDvczv5ocx",
        "outputId": "84098dd3-ec21-40f6-c5a1-76abb5a41863"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/doubleml/plm/plr.py:109: UserWarning: A learner ml_g has been provided for score = \"partialling out\" but will be ignored. \"A learner ml_g is not required for estimation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              coef   std err         t     P>|t|     2.5 %    97.5 %\n",
            "uv_index  0.013048  0.010825  1.205318  0.228081 -0.008169  0.034264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from doubleml import DoubleMLData, DoubleMLPLR\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "# Prepare your data as before\n",
        "y_col = 'aggemp'\n",
        "treatment_col = 'uv_index' # mhtx is a continuous treatment variable\n",
        "x_cols = [\n",
        "    'gfcf', 'rnd', 'internet', 'mobile', 'fdi',\n",
        "    'lnwages', 'tariff', 'msch', 'reer', 'dmy_uvindex'\n",
        "]\n",
        "\n",
        "# Drop missing values in required columns\n",
        "df_plr = df[[y_col, treatment_col] + x_cols].dropna()\n",
        "\n",
        "# Set up DoubleML Data for PLR\n",
        "dml_data = DoubleMLData(df_plr, y_col=y_col, d_cols=treatment_col, x_cols=x_cols)\n",
        "\n",
        "# Specify Machine Learning Models\n",
        "ml_g = GradientBoostingRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_m = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
        "ml_l = RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42) # Added ml_l\n",
        "\n",
        "# Fit DoubleMLPLR\n",
        "dml_plr = DoubleMLPLR(dml_data, ml_g=ml_g, ml_m=ml_m, ml_l=ml_l) # Added ml_l argument\n",
        "# Added store_models=True to the fit method\n",
        "dml_plr.fit(store_models=True)\n",
        "\n",
        "\n",
        "# Print the summary of the results\n",
        "print(dml_plr.summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rg1PGuZ663h",
        "outputId": "ab438ed2-62b0-4641-cf28-f5bb88dafaf2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/doubleml/plm/plr.py:109: UserWarning: A learner ml_g has been provided for score = \"partialling out\" but will be ignored. \"A learner ml_g is not required for estimation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              coef   std err         t     P>|t|     2.5 %   97.5 %\n",
            "uv_index  0.012396  0.010298  1.203732  0.228693 -0.007788  0.03258\n"
          ]
        }
      ]
    }
  ]
}